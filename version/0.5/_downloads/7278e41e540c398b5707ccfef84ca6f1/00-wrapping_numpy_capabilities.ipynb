{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Write user defined Operator {#ref_wrapping_numpy_capabilities}\r\n\r\nThis example shows how to create a simple DPF python plugin holding a\r\nsingle Operator. This Operator called \\\"easy_statistics\\\" computes\r\nsimple statistics quantities on a scalar Field with the help of numpy.\r\nIt\\'s a simple example displaying how routines can be wrapped in DPF\r\npython plugins.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Write Operator\r\n\r\nTo write the simplest DPF python plugins, a single python script is\r\nnecessary. An Operator implementation deriving from\r\n`ansys.dpf.core.custom_operator.CustomOperatorBase`{.interpreted-text\r\nrole=\"class\"} and a call to\r\n`ansys.dpf.core.custom_operator.record_operator`{.interpreted-text\r\nrole=\"py:func\"} are the 2 necessary steps to create a plugin. The\r\n\\\"easy_statistics\\\" Operator will take a Field in input and return the\r\nfirst quartile, the median, the third quartile and the variance. The\r\npython Operator and its recording seat in the file\r\nplugins/easy_statistics.py. This file [easy_statistics.py]{.title-ref}\r\nis downloaded and displayed here:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ansys.dpf.core import examples\n\nGITHUB_SOURCE_URL = \"https://github.com/pyansys/pydpf-core/\" \\\n                    \"raw/examples/first_python_plugins/python_plugins\"\nEXAMPLE_FILE = GITHUB_SOURCE_URL + \"/easy_statistics.py\"\noperator_file_path = examples.downloads._retrieve_file(\n    EXAMPLE_FILE, \"easy_statistics.py\", \"python_plugins\"\n)\n\nwith open(operator_file_path, \"r\") as f:\n    for line in f.readlines():\n        print('\\t\\t\\t' + line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Plugin\r\n\r\nOnce a python plugin is written, it can be loaded with the function\r\n`ansys.dpf.core.core.load_library`{.interpreted-text role=\"py:func\"}\r\ntaking as first argument the path to the directory of the plugin, as\r\nsecond argument `py_` + the name of the python script, and as last\r\nargument the function\\'s name used to record operators.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nfrom ansys.dpf import core as dpf\nfrom ansys.dpf.core import examples\n\n# python plugins are not supported in process\ndpf.start_local_server(config=dpf.AvailableServerConfigs.GrpcServer)\n\noperator_server_file_path = dpf.upload_file_in_tmp_folder(operator_file_path)\ndpf.load_library(os.path.dirname(operator_server_file_path), \"py_easy_statistics\", \"load_operators\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the Operator loaded, it can be instantiated with:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "new_operator = dpf.Operator(\"easy_statistics\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To use this new Operator, a workflow computing the norm of the\r\ndisplacement is connected to the \\\"easy_statistics\\\" Operator. Methods\r\nof the class `easy_statistics` are dynamically added thanks to the\r\nOperator\\'s specification defined in the plugin.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: graphviz\r\n\r\ndigraph foo {\r\n\r\n:   graph \\[pad=\\\"0.5\\\", nodesep=\\\"0.3\\\", ranksep=\\\"0.3\\\"\\] node\r\n    \\[shape=box, style=filled, fillcolor=\\\"#ffcc00\\\", margin=\\\"0\\\"\\];\r\n    rankdir=LR; splines=line; ds \\[label=\\\"ds\\\", shape=box,\r\n    style=filled, fillcolor=cadetblue2\\]; ds -\\> displacement\r\n    \\[style=dashed\\]; displacement -\\> norm; norm -\\> easy_statistics;\r\n\r\n}\r\n:::\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use the Custom Operator\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ds = dpf.DataSources(dpf.upload_file_in_tmp_folder(examples.static_rst))\ndisplacement = dpf.operators.result.displacement(data_sources=ds)\nnorm = dpf.operators.math.norm(displacement)\nnew_operator.inputs.connect(norm)\n\nprint(\"first quartile is\", new_operator.outputs.first_quartile())\nprint(\"median is\", new_operator.outputs.median())\nprint(\"third quartile is\", new_operator.outputs.third_quartile())\nprint(\"variance is\", new_operator.outputs.variance())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}