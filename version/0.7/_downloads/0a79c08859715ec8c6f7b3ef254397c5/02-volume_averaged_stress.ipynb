{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Average elemental stress on a given volume {#ref_volume_averaged_stress_advanced}\r\n\r\nThis example shows how to find the minimum list of surrounding elements\r\nfor a given node to get a minimum volume. For each list of elements, the\r\nelemental stress equivalent is multiplied by the volume of each element.\r\nThis result is then accumulated to divide it by the total volume.\r\n\r\n::: note\r\n::: title\r\nNote\r\n:::\r\n\r\nThis example requires the Premium ServerContext. For more information,\r\nsee `user_guide_server_context`{.interpreted-text role=\"ref\"}.\r\n:::\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ansys.dpf import core as dpf\nfrom ansys.dpf.core import examples\nfrom ansys.dpf.core import operators as ops\n\n\ndpf.set_default_server_context(dpf.AvailableServerContexts.premium)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a model targeting a given result file\r\n\r\nThe model provides easy access to the mesh and time frequency support.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dpf.Model(examples.find_complex_rst())\nmesh = model.metadata.meshed_region\n\n# Volume size to check\nvolume_check = 4.0e-11\n\n# Get all node IDs in the model to find the minimum amount of\n# surrounding elements to get a minimum volume.\nnodes = mesh.nodes.scoping\nnodes_ids = nodes.ids\nnodes_ids_to_compute = []\nfor i in range(0, 400):\n    nodes_ids_to_compute.append(nodes_ids[i])\nelements = mesh.elements.scoping\nelements_ids = elements.ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read the volume by element\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vol_op = ops.result.elemental_volume()\nvol_op.inputs.streams_container(model.metadata.streams_provider)\nvol_field = vol_op.outputs.fields_container()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Find the minimum list of elements by node to get the volume check\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# get the connectivy and inverse connecitivity fields\nconnectivity_field = mesh.elements.connectivities_field\nnodal_connectivity_field = mesh.nodes.nodal_connectivity_field\n\nnode_index_to_el_ids = {}\nnode_index_to_found_volume = {}\n# using the with statement with as_local_field allows to bring the server's\n# data locally and to work only on the local process before sending the data\n# updates to the server as the end of the with statement\n# the performances are a lot better using this syntax\n# fmt: off\nwith connectivity_field.as_local_field() as connectivity, \\\n    nodal_connectivity_field.as_local_field() as nodal_connectivity,\\\n        vol_field.as_local_field() as vol:  # fmt: on\n    for i, node in enumerate(nodes_ids_to_compute):\n\n        current_node_indexes = [i]\n        volume = 0.0\n        # Loop through recursively selecting elements attached\n        # to nodes until specified volume is reached\n        while volume_check > volume:\n            volume = 0.0\n            elements_indexes = []\n\n            # Get elements attached to nodes\n            for current_node_index in current_node_indexes:\n                elements_indexes.extend(nodal_connectivity.get_entity_data(i).flatten())\n\n            current_node_indexes = []\n            for index in elements_indexes:\n                # Sum up the volume on those elements\n                volume += vol.get_entity_data(index)[0]\n                # Get all nodes of the current elements for next iteration\n                current_node_indexes.extend(connectivity.get_entity_data(index))\n\n        node_index_to_el_ids[i] = dpf.Scoping(\n            ids=[elements_ids[index] for index in elements_indexes],\n            location=dpf.locations().elemental,\n        )\n        node_index_to_found_volume[i] = volume"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create workflow\r\n\r\nFor each list of elements surrounding nodes:\r\n\r\n-   Compute equivalent stress averaged on elements.\r\n-   Apply dot product seqv.volume.\r\n-   Sum up those on the list of elements.\r\n-   Divide this sum by the total volume on these elements.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s = model.results.stress()\nto_elemental = ops.averaging.to_elemental_fc(s)\neqv = ops.invariant.von_mises_eqv_fc(to_elemental)\nvalues_to_sum_field = eqv.outputs.fields_container()[0]\n\n# sum up the seqv by list of elements and create a Field\nseqvsum = dpf.fields_factory.create_scalar_field(len(nodes), dpf.locations.nodal)\ndataseqvsum = []\nvolsum = dpf.fields_factory.create_scalar_field(len(nodes), dpf.locations.nodal)\ndatavolsum = []\n\nwith values_to_sum_field.as_local_field() as values_to_sum:\n    with vol_field.as_local_field() as vol:\n        for key in node_index_to_el_ids:\n            ssum = 0.0\n            for id in node_index_to_el_ids[key]:\n                ssum += (\n                    values_to_sum.get_entity_data_by_id(id)[0] * vol.get_entity_data_by_id(id)[0]\n                )\n            dataseqvsum.append(ssum)\n            datavolsum.append(node_index_to_found_volume[key])\n\nseqvsum.data = dataseqvsum\nseqvsum.scoping.ids = nodes_ids_to_compute\n\nvolsum.data = datavolsum\nvolsum.scoping.ids = nodes_ids_to_compute\n\n# use component wise divide to averaged the stress by the volume\ndivide = ops.math.component_wise_divide(seqvsum, volsum)\ndivide.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plot equivalent elemental stress and volume averaged elemental equivalent stress\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mesh.plot(values_to_sum_field)\nmesh.plot(divide.outputs.field())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use the operator instead\r\n\r\nAn operator with the same algorithm has been implemented\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s_fc = s.outputs.fields_container()\nsingle_field_vol_fc = dpf.fields_container_factory.over_time_freq_fields_container([vol_field])\n\nsingle_field_fc = dpf.fields_container_factory.over_time_freq_fields_container(\n    [values_to_sum_field]\n)\n\nop = dpf.Operator(\"volume_stress\")\nop.inputs.scoping.connect(nodes)\nop.inputs.stress_fields.connect(single_field_fc)\nop.inputs.volume_fields(single_field_vol_fc)\nop.inputs.volume(volume_check * 10.0)\n\nout = op.get_output(0, dpf.types.field)\nmesh.plot(out)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}