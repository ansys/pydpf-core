{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HDF5 export and import operations {#ref_basic_hdf5}\r\n\r\nThis example shows you how to use the HDF5 format to export results and\r\nmeshed regions in an H5 file. It also demonstrates how to read results\r\nand meshed regions from the created H5 file.\r\n\r\nFirst, it exports all the results for all time frequencies, then it\r\nexports all the time sets for the results, per time set. Finally, it\r\nreads the results and compares them. For the example to run correctly,\r\nensure you do not have an existing H5 file.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import modules, instantiate model and create temporary folder\r\n\r\nImport the `dpf-core` module and its examples files.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import ansys.dpf.core as dpf\nfrom ansys.dpf.core import examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instantiate the model and the provider operators:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dpf.Model(examples.download_transient_result())\nstreams_cont = model.metadata.streams_provider.outputs.streams_container\ntime_freq_op = dpf.operators.metadata.time_freq_provider(streams_container=streams_cont)\ntime_freq_support = time_freq_op.outputs.time_freq_support()\ntime_freqs = time_freq_support.time_frequencies\n\nresult_names_on_all_time_steps = []\nresult_names_time_per_time = []\n\nnum_res = len(model.results)\nnum_sets = len(time_freqs.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a temporary folder for outputs:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tmpdir = dpf.core.make_tmp_dir_server(dpf.SERVER)\nfiles = [\n    dpf.path_utilities.join(tmpdir, \"file_on_all_time_steps.h5\"),\n    dpf.path_utilities.join(tmpdir, \"file_time_per_time.h5\"),\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use H5 serialization operator\r\n\r\nExport all results on all time frequencies:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_serialization_op_all_times = dpf.operators.serialization.hdf5dpf_generate_result_file()\nh5_serialization_op_all_times.inputs.filename.connect(files[0])\nh5_serialization_op_all_times.inputs.mesh_provider_out.connect(model.metadata.meshed_region)\nh5_serialization_op_all_times.inputs.time_freq_support_out.connect(time_freq_support)\n\nfor i, res in enumerate(model.results):\n    res_name = \"result_\" + res().name\n    result_names_on_all_time_steps.append(res_name)\n    h5_serialization_op_all_times.connect(2 * i + 4, res_name)\n    h5_serialization_op_all_times.connect(2 * i + 5, res.on_all_time_freqs())\n\nh5_all_times_ds = h5_serialization_op_all_times.outputs.data_sources()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Export all the results, time set per time set:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_serialization_op_set_per_set = dpf.operators.serialization.hdf5dpf_generate_result_file()\nh5_serialization_op_set_per_set.inputs.filename.connect(files[1])\nh5_serialization_op_set_per_set.inputs.mesh_provider_out.connect(model.metadata.meshed_region)\nh5_serialization_op_set_per_set.inputs.time_freq_support_out.connect(time_freq_support)\n\nfor j, freq in enumerate(time_freqs.data):\n    for i, res in enumerate(model.results):\n        res_name = \"result_\" + res().name + \"_time_\" + str(freq)\n        result_names_time_per_time.append(res_name)\n        h5_serialization_op_set_per_set.connect(2 * (j * num_res + i) + 4, res_name)\n        h5_serialization_op_set_per_set.connect(\n            2 * (j * num_res + i) + 5, res.on_time_scoping(j + 1).eval()\n        )\n\nh5_set_per_set_ds = h5_serialization_op_set_per_set.outputs.data_sources()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use H5 reading operator\r\n\r\nRead the results from all time steps files:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_stream_prov_op = dpf.operators.metadata.streams_provider()\nh5_stream_prov_op.inputs.data_sources.connect(h5_all_times_ds)\nres_deser_all_times_list = []\nh5_read_op = dpf.operators.serialization.hdf5dpf_custom_read()\nh5_read_op.inputs.streams.connect(h5_stream_prov_op.outputs)\nfor i, res_name in enumerate(result_names_on_all_time_steps):\n    h5_read_op.inputs.result_name.connect(res_name)\n    res_deser = h5_read_op.outputs.field_or_fields_container_as_fields_container()\n    res_deser_all_times_list.append(res_deser)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the meshed region from all time steps file:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mesh_prov_op = dpf.operators.mesh.mesh_provider()\nmesh_prov_op.inputs.streams_container.connect(h5_stream_prov_op.outputs)\nmesh_deser_all_times = mesh_prov_op.outputs.mesh()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the results from the time set per set file:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_stream_prov_op_2 = dpf.operators.metadata.streams_provider()\nh5_stream_prov_op_2.inputs.data_sources.connect(h5_set_per_set_ds)\nres_deser_set_per_set_list = []\nh5_read_op_2 = dpf.operators.serialization.hdf5dpf_custom_read()\nh5_read_op_2.inputs.streams.connect(h5_stream_prov_op_2.outputs)\nfor i, res_name in enumerate(result_names_time_per_time):\n    h5_read_op_2.inputs.result_name.connect(res_name)\n    res_deser = h5_read_op_2.outputs.field_or_fields_container_as_fields_container()\n    res_deser_set_per_set_list.append(res_deser)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the meshed region from all time steps files:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mesh_prov_op_2 = dpf.operators.mesh.mesh_provider()\nmesh_prov_op_2.inputs.streams_container.connect(h5_stream_prov_op_2.outputs)\nmesh_deser_set_per_set = mesh_prov_op_2.outputs.mesh()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compare results\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print global data:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Number of results is: \" + str(num_res))\nprint(\"Number of time sets is: \" + str(num_sets))\nprint(\"Results names for 'all time steps' file: \")\nprint(result_names_on_all_time_steps)\nprint(\"Results names for 'set per set' file: \")\nprint(result_names_time_per_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "compare first result at second time set:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fc_all_steps_first_step_first_res = res_deser_all_times_list[0].get_field_by_time_id(2)  # set 1\nmesh_deser_all_times.plot(fc_all_steps_first_step_first_res)\n\nmesh_deser_set_per_set.plot(res_deser_set_per_set_list[num_res * 1 + 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "compare 4th result at 6 time set:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "to_nodal_op = dpf.operators.averaging.to_nodal_fc()\n\nfc_all_steps_first_step_first_res = res_deser_all_times_list[3].get_field_by_time_id(6)  # set 6\nmesh_deser_all_times.plot(\n    dpf.operators.averaging.to_nodal(fc_all_steps_first_step_first_res).outputs.field()\n)\n\nmesh_deser_set_per_set.plot(\n    dpf.operators.averaging.to_nodal(res_deser_set_per_set_list[num_res * 5 + 3]).outputs.field()\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}