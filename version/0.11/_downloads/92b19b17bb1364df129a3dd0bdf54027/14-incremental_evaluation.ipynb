{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use incremental evaluation helper {#ref_incremental_evaluation}\r\n\r\nThis example shows you how to use the incremental evaluation helper.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import necessary modules\nfrom ansys.dpf import core as dpf\nfrom ansys.dpf.core import examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieve an example to instantiate a DataSources object\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = examples.download_transient_result()\nds = dpf.DataSources(path)\n\n# From the DataSources object we can retrieve the scoping\n# In this example we want to compute the min/max for all the time sets\ntf_provider = dpf.operators.metadata.time_freq_provider(data_sources=ds)\ntf_support = tf_provider.get_output(output_type=dpf.types.time_freq_support)\nscoping = dpf.time_freq_scoping_factory.scoping_on_all_time_freqs(tf_support)\n\n# If you don't need to reuse TimeFreqSupport you could also use the DataSources\n# scoping = dpf.time_freq_scoping_factory.scoping_on_all_time_freqs(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining the workflow to exploit\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Instantiating a streams_provider is important when dealing with incremental evaluation\n# due to multiple reuses of operators\nstreams_provider = dpf.operators.metadata.streams_provider(data_sources=ds)\n\n# Defining the main workflow\nresult_op = dpf.operators.result.stress(\n    data_sources=ds, time_scoping=scoping, streams_container=streams_provider\n)\nnorm_fc = dpf.operators.math.norm_fc(result_op)\nfinal_op = dpf.operators.min_max.min_max_fc_inc(norm_fc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtain a new operator to retrieve outputs from\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Workflow is adapted from the first and the last operator in the current workflow\n# Scoping is important to split the workload into chunks\nnew_end_op = dpf.split_workflow_in_chunks(result_op, final_op, scoping)\n\n\n# Obtain results on the same pin numbers\nmin = new_end_op.get_output(0, dpf.types.field)\nmax = new_end_op.get_output(1, dpf.types.field)\n\n# Plot results\nimport matplotlib.pyplot as plt\n\nx = tf_support.time_frequencies.data\nplt.plot(x, min.data, \"b\", label=\"Min\")\nplt.plot(x, max.data, \"r\", label=\"Max\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Stress\")\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}