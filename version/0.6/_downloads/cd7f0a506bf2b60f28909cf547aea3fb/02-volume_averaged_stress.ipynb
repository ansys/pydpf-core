{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Average elemental stress on a given volume {#ref_volume_averaged_stress_advanced}\r\n\r\nThis example shows how to find the minimum list of surrounding elements\r\nfor a given node to get a minimum volume. For each list of elements, the\r\nelemental stress equivalent is multiplied by the volume of each element.\r\nThis result is then accumulated to divide it by the total volume.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ansys.dpf import core as dpf\nfrom ansys.dpf.core import examples\nfrom ansys.dpf.core import operators as ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a model targeting a given result file\r\n\r\nThe model provides easy access to the mesh and time frequency support.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dpf.Model(examples.find_complex_rst())\nmesh = model.metadata.meshed_region\n\n# Volume size to check\nvolume_check = 4.0e-11\n\n# Get all node IDs in the model to find the minimum amount of\n# surrounding elements to get a minimum volume.\nnodes = mesh.nodes.scoping\nnodes_ids = nodes.ids\nnodes_ids_to_compute = []\nfor i in range(0, 400):\n    nodes_ids_to_compute.append(nodes_ids[i])\nelements = mesh.elements.scoping\nelements_ids = elements.ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read the volume by element\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vol_op = ops.result.elemental_volume()\nvol_op.inputs.streams_container(model.metadata.streams_provider)\nvol_field = vol_op.outputs.fields_container()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Find the minimum list of elements by node to get the volume check\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# get the connectivy and inverse connecitivity fields\nconnectivity_field = mesh.elements.connectivities_field\nnodal_connectivity_field = mesh.nodes.nodal_connectivity_field\n\nnode_index_to_el_ids = {}\nnode_index_to_found_volume = {}\n# using the with statement with as_local_field allows to bring the server's\n# data locally and to work only on the local process before sending the data\n# updates to the server as the end of the with statement\n# the performances are a lot better using this syntax\nwith connectivity_field.as_local_field() as connectivity:\n    with nodal_connectivity_field.as_local_field() as nodal_connectivity:\n        with vol_field.as_local_field() as vol:\n            for i, node in enumerate(nodes_ids_to_compute):\n\n                current_node_indexes = [i]\n                volume = 0.0\n                # Loop through recursively selecting elements attached\n                # to nodes until specified volume is reached\n                while volume_check > volume:\n                    volume = 0.0\n                    elements_indexes = []\n                    # get elements attached to nodes\n                    for current_node_index in current_node_indexes:\n                        elements_indexes.extend(\n                            nodal_connectivity.get_entity_data(i).flatten()\n                        )\n\n                    current_node_indexes = []\n                    for index in elements_indexes:\n                        # sum up the volume on those elements\n                        volume += vol.get_entity_data(index)[0]\n\n                        # get all nodes of the current elements for next iteration\n                        current_node_indexes.extend(connectivity.get_entity_data(index))\n                node_index_to_el_ids[i] = dpf.Scoping(\n                    ids=[elements_ids[index] for index in elements_indexes],\n                    location=dpf.locations().elemental,\n                )\n                node_index_to_found_volume[i] = volume"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create workflow\r\n\r\nFor each list of elements surrounding nodes:\r\n\r\n-   Compute equivalent stress averaged on elements.\r\n-   Apply dot product seqv.volume.\r\n-   Sum up those on the list of elements.\r\n-   Divide this sum by the total volume on these elements.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s = model.results.stress()\nto_elemental = ops.averaging.to_elemental_fc(s)\neqv = ops.invariant.von_mises_eqv_fc(to_elemental)\nvalues_to_sum_field = eqv.outputs.fields_container()[0]\n\n# sum up the seqv by list of elements and create a Field\nseqvsum = dpf.fields_factory.create_scalar_field(len(nodes), dpf.locations.nodal)\ndataseqvsum = []\nvolsum = dpf.fields_factory.create_scalar_field(len(nodes), dpf.locations.nodal)\ndatavolsum = []\n\nwith values_to_sum_field.as_local_field() as values_to_sum:\n    with vol_field.as_local_field() as vol:\n        for key in node_index_to_el_ids:\n            ssum = 0.0\n            for id in node_index_to_el_ids[key]:\n                ssum += (\n                        values_to_sum.get_entity_data_by_id(id)[0]\n                        * vol.get_entity_data_by_id(id)[0]\n                )\n            dataseqvsum.append(ssum)\n            datavolsum.append(node_index_to_found_volume[key])\n\nseqvsum.data = dataseqvsum\nseqvsum.scoping.ids = nodes_ids_to_compute\n\nvolsum.data = datavolsum\nvolsum.scoping.ids = nodes_ids_to_compute\n\n# use component wise divide to averaged the stress by the volume\ndivide = ops.math.component_wise_divide(seqvsum, volsum)\ndivide.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plot equivalent elemental stress and volume averaged elemental equivalent stress\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mesh.plot(values_to_sum_field)\nmesh.plot(divide.outputs.field())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use the operator instead\r\n\r\nAn operator with the same algorithm has been implemented\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "s_fc = s.outputs.fields_container()\nsingle_field_vol_fc = dpf.fields_container_factory.over_time_freq_fields_container(\n    [vol_field]\n)\n\nsingle_field_fc = dpf.fields_container_factory.over_time_freq_fields_container(\n    [values_to_sum_field]\n)\n\nop = dpf.Operator(\"volume_stress\")\nop.inputs.scoping.connect(nodes)\nop.inputs.stress_fields.connect(single_field_fc)\nop.inputs.volume_fields(single_field_vol_fc)\nop.inputs.volume(volume_check * 10.0)\n\nout = op.get_output(0, dpf.types.field)\nmesh.plot(out)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}