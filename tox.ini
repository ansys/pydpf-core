# This is work in progress
# Testing workflow in CI is gradually being transferred to tox

[tox]
description = Default tox environment list and core configurations

# List all tests to run in parallel or sequential mode here
labels =
    tests = test-api,test-launcher,test-server,test-local_server,test-multi_server,test-remote_workflow,test-remote_operator,test-workflow,test-service,test-operators

isolated_build_env = build

[testenv]
description = Default configuration for test environments, unless overridden

pass_env =
    PACKAGE_NAME
    MODULE
    ANSYS_DPF_ACCEPT_LA
    ANSYSLMD_LICENSE_FILE
    AWP_ROOT242

package = external # To allow custom wheel builds

[testenv:build_external]
description = Environment for custom build of package wheels, solves PyDPF custom wheel building requirement

allowlist_externals =
    bash

package_glob = {toxinidir}{/}dist{/}ansys_dpf_core*

commands = 
    # Build the wheel
    bash -c '\
    if [ {on_platform} == "linux" ]; then \
        export platform="manylinux_2_17"; \
    elif [ {on_platform} == "win32" ]; then \
        export platform="win"; \
    else \
        echo "Unknown OS"; \
    fi; \
    echo $platform; \
    python .ci/build_wheel.py -p $platform -w'

[testenv:runtests-{sequential,parallel}]
description = Environment to allow executing some commands before test run, and after test run
# In PyDPF, test files are organized prior to testing. This environment helps to achieve the same effect, ensuring
# test files are organized before running tests and reverted after the tests finish running.
# Servers can always be killed before test runs to ensure a clean state.

skip_install = True

allowlist_externals =
    tox

deps =
    psutil

commands_pre = 
    # Clear any running servers that may be locking resources
    python -c "import psutil; proc_name = 'Ans.Dpf.Grpc'; nb_procs = len([proc.kill() for proc in psutil.process_iter() if proc_name in proc.name()]); \
    print(f'Killed \{nb_procs} \{proc_name} processes.')"

    # Organize test files
    python -c "\
    import os, shutil; \
    test_data=['test_launcher','test_server','test_local_server','test_multi_server','test_workflow','test_remote_workflow','test_remote_operator','test_service','test_custom_type_field']; \
    [(os.makedirs(d, exist_ok=True), shutil.copy('tests/conftest.py', d), shutil.copy(f'tests/\{d}.py', d) if os.path.exists(f'tests/\{d}.py') else None) for d in test_data]; \
    [os.remove(f'tests/\{d}.py') for d in test_data if os.path.exists(f'tests/\{d}.py')]"

# Run tests
commands =
    sequential: tox -m tests
    parallel: tox --parallel -m tests

commands_post = 
    # Revert project layout to previous state
    python -c "\
    import os, shutil; \
    test_data=['test_launcher','test_server','test_local_server','test_multi_server','test_workflow','test_remote_workflow','test_remote_operator','test_service', 'test_custom_type_field']; \ 
    [shutil.move(f'\{d}/\{d}.py', f'tests/\{d}.py') for d in test_data if os.path.exists(f'\{d}/\{d}.py')]; \
    [shutil.rmtree(d) for d in test_data if os.path.exists(d)]"

    # Clear any running servers that may be locking resources
    python -c "import psutil; proc_name = 'Ans.Dpf.Grpc'; nb_procs = len([proc.kill() for proc in psutil.process_iter() if proc_name in proc.name()]); \
    print(f'Killed \{nb_procs} \{proc_name} processes.')"

[testenv:test-{api,launcher,server,local_server,multi_server,remote_workflow,remote_operator,workflow,service,operators}]
description = Environment where project testing configuration is defined

setenv =
    # Pytest extra arguments
    COVERAGE = --cov=ansys.dpf.core --cov-report=xml --cov-report=html --log-level=ERROR --cov-append
    RERUNS = -reruns=2 --reruns-delay=1
    DEBUG = -v -s --durations=10 --durations-min=1.0

    api: JUNITXML = --junitxml=tests/junit/test-results.xml
    launcher: JUNITXML = --junitxml=tests/junit/test-results2.xml
    server: JUNITXML = --junitxml=tests/junit/test-results3.xml
    local_server: JUNITXML = --junitxml=tests/junit/test-results4.xml
    multi_server: JUNITXML = --junitxml=tests/junit/test-results5.xml
    remote_workflow: JUNITXML = --junitxml=tests/junit/test-results6.xml
    remote_operator: JUNITXML = --junitxml=tests/junit/test-results7.xml
    workflow: JUNITXML = test_workflow--junitxml=tests/junit/test-results8.xml
    service: JUNITXML = --junitxml=tests/junit/test-results9.xml
    operators: JUNITXML = --junitxml=../tests/junit/test-results12.xml

    # Tests sets
    api: PYTEST_PYTHON_FILES = tests
    launcher: PYTEST_PYTHON_FILES = test_launcher
    server: PYTEST_PYTHON_FILES = test_server
    local_server: PYTEST_PYTHON_FILES = test_local_server
    multi_server: PYTEST_PYTHON_FILES = test_multi_server
    remote_workflow: PYTEST_PYTHON_FILES = test_remote_workflow
    remote_operator: PYTEST_PYTHON_FILES = test_remote_operator
    workflow: PYTEST_PYTHON_FILES = test_workflow
    service: PYTEST_PYTHON_FILES = test_service
    operators: PYTEST_PYTHON_FILES = tests/operators

deps = 
    -r requirements/requirements_test.txt

commands =
    pytest {env:PYTEST_PYTHON_FILES} {env:DEBUG} {env:COVERAGE} {env:RERUNS} {env:JUNITXML}