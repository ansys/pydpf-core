# This is work in progress, testing workflow in local/CI is gradually being transferred to tox

# Usage instructions:

# `tox` will run all tests sequentially, `tox --parallel` will run all tests in parallel (much faster).
# Run specific selection of tests with `tox -e pretest,<list-of-tests>,posttest` e.g., `tox -e pretest,test-api,test-launcher,posttest`
# `--parallel` flag can be passed when running specific selections.

# For packaging, build wheels for specific platform with `tox -e build-wheel -- <platform_name>`.
# If `tox -e build-wheel` is run without passing a platform, tox will automatically build the ffl wheels based on the operating system
# on which it is executing: windows -> "win_amd64", linux -> "manylinux_2_17_x86_64", mac -> "any"

[tox]
description = Default tox environment list and core configurations

envlist = pretest,test-{api,launcher,server,local_server,multi_server,remote_workflow,remote_operator,workflow,service,operators},posttest

isolated_build_env = build

[testenv]
description = Default configuration for test environments, unless overridden

pass_env =
    PACKAGE_NAME
    MODULE
    ANSYS_DPF_ACCEPT_LA
    ANSYSLMD_LICENSE_FILE
    AWP_ROOT242

[testenv:pretest]
description = Environment to kill servers and organize test files prior to testing

deps =
    psutil

skip_install = True

commands = 
    # Clear any running servers that may be locking resources
    python -c "import psutil; proc_name = 'Ans.Dpf.Grpc'; nb_procs = len([proc.kill() for proc in psutil.process_iter() if proc_name in proc.name()]); \
    print(f'Killed \{nb_procs} \{proc_name} processes.')"

    # Organize test files
    python -c "\
    import os, shutil; \
    test_data=['test_launcher','test_server','test_local_server','test_multi_server','test_workflow','test_remote_workflow','test_remote_operator','test_service','test_custom_type_field']; \
    [(os.makedirs(d, exist_ok=True), shutil.copy('tests/conftest.py', d), shutil.copy(f'tests/\{d}.py', d) if os.path.exists(f'tests/\{d}.py') else None) for d in test_data]; \
    [os.remove(f'tests/\{d}.py') for d in test_data if os.path.exists(f'tests/\{d}.py')]"

[testenv:posttest]
description = Environment to kill servers and revert test files to original state after testing

depends = pretest, test-{api,launcher,server,local_server,multi_server,remote_workflow,remote_operator,workflow,service,operators}

deps =
    psutil

skip_install = True

commands = 
    # Revert project layout to previous state
    python -c "\
    import os, shutil; \
    test_data=['test_launcher','test_server','test_local_server','test_multi_server','test_workflow','test_remote_workflow','test_remote_operator','test_service', 'test_custom_type_field']; \ 
    [shutil.move(f'\{d}/\{d}.py', f'tests/\{d}.py') for d in test_data if os.path.exists(f'\{d}/\{d}.py')]; \
    [shutil.rmtree(d) for d in test_data if os.path.exists(d)]"

    # Clear any running servers that may be locking resources
    python -c "import psutil; proc_name = 'Ans.Dpf.Grpc'; nb_procs = len([proc.kill() for proc in psutil.process_iter() if proc_name in proc.name()]); \
    print(f'Killed \{nb_procs} \{proc_name} processes.')"

[testenv:test-{api,launcher,server,local_server,multi_server,remote_workflow,remote_operator,workflow,service,operators}]
description = Environment where project testing configuration is defined

depends = pretest

setenv =
    # Pytest extra arguments
    COVERAGE = --cov=ansys.dpf.core --cov-report=xml --cov-report=html --log-level=ERROR --cov-append
    RERUNS = --reruns=2 --reruns-delay=1
    DEBUG = -v -s --durations=10 --durations-min=1.0

    api: JUNITXML = --junitxml=tests/junit/test-results.xml
    launcher: JUNITXML = --junitxml=tests/junit/test-results2.xml
    server: JUNITXML = --junitxml=tests/junit/test-results3.xml
    local_server: JUNITXML = --junitxml=tests/junit/test-results4.xml
    multi_server: JUNITXML = --junitxml=tests/junit/test-results5.xml
    remote_workflow: JUNITXML = --junitxml=tests/junit/test-results6.xml
    remote_operator: JUNITXML = --junitxml=tests/junit/test-results7.xml
    workflow: JUNITXML = --junitxml=tests/junit/test-results8.xml
    service: JUNITXML = --junitxml=tests/junit/test-results9.xml
    operators: JUNITXML = --junitxml=../tests/junit/test-results12.xml

    # Tests sets
    api: PYTEST_PYTHON_FILES = tests
    launcher: PYTEST_PYTHON_FILES = test_launcher
    server: PYTEST_PYTHON_FILES = test_server
    local_server: PYTEST_PYTHON_FILES = test_local_server
    multi_server: PYTEST_PYTHON_FILES = test_multi_server
    remote_workflow: PYTEST_PYTHON_FILES = test_remote_workflow
    remote_operator: PYTEST_PYTHON_FILES = test_remote_operator
    workflow: PYTEST_PYTHON_FILES = test_workflow
    service: PYTEST_PYTHON_FILES = test_service
    operators: PYTEST_PYTHON_FILES = tests/operators

deps = 
    -r requirements/requirements_test.txt

commands =
    pytest {env:PYTEST_PYTHON_FILES} {env:DEBUG} {env:COVERAGE} {env:RERUNS} {env:JUNITXML}

[testenv:build-wheel]
description = Environment for custom build of package wheels

skip_install = True

commands = 
    python .ci/build_wheel.py -p {posargs:{on_platform}} -w