# This is work in progress, testing workflow in local/CI is gradually being transferred to tox

# Usage instructions:

# `tox` will run all "envlist" tests sequentially, `tox --parallel` same tests in parallel (much faster).
# "othertests" are advisable to run sequentially as parallel running can lead to segmentation faults and weird errors. Hence,
# the reason for their separation. `tox -m othertests` will run these tests sequentially.

# Run specific selection of tests with `tox -e pretest,<list-of-tests>,posttest,kill-servers` e.g., `tox -e pretest,test-api,test-launcher,posttest,kill-servers`
# `--parallel` flag can also be passed when running specific selections.

# For packaging, build wheels for specific platform with `tox -e build-wheel -- <platform_name>`.
# If `tox -e build-wheel` is run without passing a platform, tox will automatically build the ffl wheels based on the operating system
# on which it is executing: windows -> "win_amd64", linux -> "manylinux_2_17_x86_64", mac -> "any"

# For html documentation generation, run `tox -e doc-html`. To clean previously existing documentation before generating
# a new one, run `tox -e doc-clean,doc-html`

# Current tox configuration can automatically detect DPF server installation in these cases:
# - Unified install
# - if ANSYS_DPF_PATH is set and points to a valid DPF server installation
# Which means invoking tox with previous commands necessitate having a server available via above methods

# Understandably for development purposes, more flexibility may be desired and there are various ways of invoking tox to achieve desired effects.
# For example, to use a standalone dpf server (present in ansys_dpf_server_win_v2025.1.pre0/ directory) in editable mode in each tox environment,
# you can do something like `tox -m othertests -x testenv.deps+="-e ansys_dpf_server_win_v2025.1.pre0"`.
# The tox documentation should be consulted for a quick overview of different CLI flags that can be used to customize invocation.

[tox]
description = Default tox environment list and core configurations

envlist = pretest,test-{api,documentation,launcher,server,local_server,multi_server,api_entry,custom_type_field,operators,workflow,remote_workflow,remote_operator,service,server_errors},posttest,kill-servers

labels =
    localparalleltests = pretest,test-{api,documentation,launcher,server,local_server,multi_server,custom_type_field,operators,server_errors},posttest,kill-servers
    othertests = pretest,test-{workflow,remote_workflow,remote_operator,service},posttest,kill-servers
    ciparalleltests = test-{api,documentation,launcher,local_server,multi_server,custom_type_field,operators,server_errors},kill-servers
    
isolated_build_env = build

[testenv]
description = Default configuration for test environments, unless overridden

uv_seed = true

pass_env =
    PACKAGE_NAME
    MODULE
    ANSYS_DPF_ACCEPT_LA
    ANSYSLMD_LICENSE_FILE
    AWP_ROOT*
    ANSYS_DPF_PATH
    ANSYS_GRPC_CERTIFICATES
    DPF_DEFAULT_GRPC_MODE

deps = 
    -r requirements/requirements_test.txt

parallel_show_output = True

[testenv:build-wheel]
description = Environment for custom build of package wheels

skip_install = True

deps =
    -r requirements/requirements_build.txt

commands = 
    python .ci/build_wheel.py -p {posargs:{on_platform}} -w

[testenv:kill-servers]
description = Environment for clearing running servers

depends = test-{api,documentation,launcher,server,local_server,multi_server,remote_workflow,remote_operator,workflow,service,api_entry,custom_type_field,operators,server_errors}

deps =
    psutil

commands_pre =

skip_install = True

commands = 
    python -c "import psutil; proc_name = 'Ans.Dpf.Grpc'; nb_procs = len([proc.kill() for proc in psutil.process_iter() if proc_name in proc.name()]); \
    print(f'Killed \{nb_procs} \{proc_name} processes.')"

[testenv:pretest]
description = Environment to organize test files prior to testing

skip_install = True

deps =

commands_pre =

commands = 
    python -c "\
    import os, shutil; \
    test_data=['test_documentation','test_launcher','test_server','test_local_server','test_multi_server','test_workflow','test_remote_workflow','test_remote_operator','test_service','test_custom_type_field','test_server_errors']; \
    [(os.makedirs(d, exist_ok=True), shutil.copy('tests/conftest.py', d), shutil.copy(f'tests/\{d}.py', d) if os.path.exists(f'tests/\{d}.py') else None) for d in test_data]; \
    [os.remove(f'tests/\{d}.py') for d in test_data if os.path.exists(f'tests/\{d}.py')]"

[testenv:posttest]
description = Environment to revert test files to original state after testing

depends = pretest, test-{api,documentation,launcher,server,local_server,multi_server,remote_workflow,remote_operator,workflow,service,api_entry,custom_type_field,operators,server_errors}

skip_install = True

deps =

commands_pre =

commands = 
    python -c "\
    import os, shutil; \
    test_data=['test_documentation','test_launcher','test_server','test_local_server','test_multi_server','test_workflow','test_remote_workflow','test_remote_operator','test_service', 'test_custom_type_field','test_server_errors']; \
    [shutil.move(f'\{d}/\{d}.py', f'tests/\{d}.py') for d in test_data if os.path.exists(f'\{d}/\{d}.py')]; \
    [shutil.rmtree(d) for d in test_data if os.path.exists(d)]"

[testenv:test-{api,documentation,launcher,server,local_server,multi_server,remote_workflow,remote_operator,workflow,service,api_entry,custom_type_field,operators,server_errors}]
description =
    Environment for running
    api: api tests
    documentation: documentation tests
    launcher: launcher tests
    server: server tests
    local_server: local server tests
    multi_server: multiple server tests
    remote_workflow: remote workflow tests
    remote_operator: remote operator tests
    workflow: workflow tests
    service: service tests
    api_entry: api entry tests
    custom_type_field: custom-type field tests
    operators: operators tests
    server_errors: server error wrapping tests

depends = pretest

setenv =
    # Pytest extra arguments
    COVERAGE = --cov=ansys.dpf.core --log-level=ERROR --cov-report=
    RERUNS = --reruns=2 --reruns-delay=1
    DEBUG = -v -s --durations=10 --durations-min=1.0
    COVERAGE_FILE = {work_dir}/.cov/.coverage.{env_name}

    api: JUNITXML = --junitxml=tests/junit/test-results.xml -o junit_family=legacy
    launcher: JUNITXML = --junitxml=tests/junit/test-results2.xml -o junit_family=legacy
    server: JUNITXML = --junitxml=tests/junit/test-results3.xml -o junit_family=legacy
    local_server: JUNITXML = --junitxml=tests/junit/test-results4.xml -o junit_family=legacy
    multi_server: JUNITXML = --junitxml=tests/junit/test-results5.xml -o junit_family=legacy
    remote_workflow: JUNITXML = --junitxml=tests/junit/test-results6.xml -o junit_family=legacy
    remote_operator: JUNITXML = --junitxml=tests/junit/test-results7.xml -o junit_family=legacy
    workflow: JUNITXML = --junitxml=tests/junit/test-results8.xml -o junit_family=legacy
    service: JUNITXML = --junitxml=tests/junit/test-results9.xml -o junit_family=legacy
    api_entry: JUNITXML = --junitxml=tests/junit/test-results10.xml -o junit_family=legacy
    custom_type_field: JUNITXML = --junitxml=tests/junit/test-results11.xml -o junit_family=legacy
    operators: JUNITXML = --junitxml=tests/junit/test-results12.xml -o junit_family=legacy
    documentation: JUNITXML = --junitxml=tests/junit/test-results13.xml -o junit_family=legacy
    server_errors: JUNITXML = --junitxml=tests/junit/test-results14.xml -o junit_family=legacy

    # Tests sets
    api: PYTEST_PYTHON_FILES = tests
    launcher: PYTEST_PYTHON_FILES = test_launcher
    server: PYTEST_PYTHON_FILES = test_server
    local_server: PYTEST_PYTHON_FILES = test_local_server
    multi_server: PYTEST_PYTHON_FILES = test_multi_server
    remote_workflow: PYTEST_PYTHON_FILES = test_remote_workflow
    remote_operator: PYTEST_PYTHON_FILES = test_remote_operator
    workflow: PYTEST_PYTHON_FILES = test_workflow
    service: PYTEST_PYTHON_FILES = test_service
    api_entry: PYTEST_PYTHON_FILES = tests/entry
    custom_type_field: PYTEST_PYTHON_FILES = test_custom_type_field
    operators: PYTEST_PYTHON_FILES = tests/operators
    documentation: PYTEST_PYTHON_FILES = test_documentation
    server_errors: PYTEST_PYTHON_FILES = test_server_errors

    TEMP = {env_tmp_dir}
    TMP = {env_tmp_dir}

commands =
    python -m pytest {env:PYTEST_PYTHON_FILES} {env:DEBUG} {env:RERUNS} {env:JUNITXML} {env:COVERAGE} {posargs}

[testenv:covreport]
description = Environment for combining coverage reports

skip_install = true

deps = coverage

change_dir = {work_dir}/.cov

commands = 
    coverage combine
    coverage xml
    coverage erase # deletes only .coverage data file, otherwise codecov action will generate coverage.xml report again

[testenv:doc-{clean,links,html}]
description = 
    Environment for 
    html: html documentation generation
    clean: cleaning previously generated html documentation
    links: verifying the integrity of external links within the documentation

pass_env = 
    {[testenv]pass_env}
    BUILD_API
    BUILD_EXAMPLES
    BUILD_TUTORIALS

setenv =
    SOURCE_DIR = doc/source
    BUILD_DIR = doc/build
    BUILDER_OPTS = --color -j auto
    links: BUILDER = linkcheck
    html: BUILDER = html

skip_install =
    clean: True

extras =
    html: graphics

deps =
    clean:
    links,html: -r requirements/requirements_docs.txt

commands_pre =
    # Clear any running servers that may be locking resources
    html,links: python -c "import psutil; proc_name = 'Ans.Dpf.Grpc'; nb_procs = len([proc.kill() for proc in psutil.process_iter() if proc_name in proc.name()]); \
    html,links: print(f'Killed \{nb_procs} \{proc_name} processes.')"

commands =
    # Remove previously rendered documentation
    clean: python -c "import shutil, sys; shutil.rmtree(sys.argv[1], ignore_errors=True)" "{toxinidir}/{env:BUILD_DIR}"

    # Clean examples from previous build
    clean: python -c "\
    clean: from os.path import exists; import shutil; \
    clean: [(shutil.rmtree(p) if exists(p) else None) for p in ['{env:SOURCE_DIR}/images/auto-generated']]; \
    clean: [(shutil.move(src, dst) if exists(src) else None) for src, dst in \
    clean: [('{env:SOURCE_DIR}/examples/07-python-operators/plugins', '{env:SOURCE_DIR}/_temp/plugins'), \
    clean: ('{env:SOURCE_DIR}/examples/04-advanced/02-volume_averaged_stress', '{env:SOURCE_DIR}/_temp/04_advanced'), \
    clean: ('{env:SOURCE_DIR}/examples/12-fluids/02-fluids_results', '{env:SOURCE_DIR}/_temp/12_fluids')]]; \
    clean: [shutil.rmtree(p) for p in ['{env:SOURCE_DIR}/examples'] if exists(p)]; \
    clean: [(shutil.move(src, dst) if exists(src) else None) for src, dst in \
    clean: [('{env:SOURCE_DIR}/_temp/plugins', '{env:SOURCE_DIR}/examples/07-python-operators/plugins'), \
    clean: ('{env:SOURCE_DIR}/_temp/04_advanced', '{env:SOURCE_DIR}/examples/04-advanced/02-volume_averaged_stress'), \
    clean: ('{env:SOURCE_DIR}/_temp/12_fluids', '{env:SOURCE_DIR}/examples/12-fluids/02-fluids_results')]]; \
    clean: [shutil.rmtree(p) for p in ['{env:SOURCE_DIR}/_temp'] if exists(p)]"

    # Build documentation
    html,links: {env_bin_dir}/sphinx-build -b {env:BUILDER} {env:SOURCE_DIR} {env:BUILD_DIR}/{env:BUILDER} {env:BUILDER_OPTS}

commands_post =
    # Clear any running servers that may be locking resources
    html,links: python -c "import psutil; proc_name = 'Ans.Dpf.Grpc'; nb_procs = len([proc.kill() for proc in psutil.process_iter() if proc_name in proc.name()]); \
    html,links: print(f'Killed \{nb_procs} \{proc_name} processes.')"
