{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Distributed modal superposition\nThis example shows how distributed files can be read and expanded\non distributed processes. The modal basis (2 distributed files) is read\non 2 remote servers and the modal response reading and the expansion is\ndone on a third server.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import dpf module and its examples files\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ansys.dpf import core as dpf\nfrom ansys.dpf.core import examples\nfrom ansys.dpf.core import operators as ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create the template workflow\nthis workflow will provide the modal basis and the mesh for each domain\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "template_workflow = dpf.Workflow()\ndisplacement = ops.result.displacement()\nmesh = ops.mesh.mesh_provider()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add the operators to the template workflow and name its inputs and outputs\nOnce workflow's inputs and outputs are named, they can be connected later on\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "template_workflow.add_operators([displacement])\ntemplate_workflow.set_input_name(\"data_sources\", displacement.inputs.data_sources)\ntemplate_workflow.set_input_name(\"data_sources\", mesh.inputs.data_sources)\ntemplate_workflow.set_output_name(\"out\", displacement.outputs.fields_container)\ntemplate_workflow.set_output_name(\"outmesh\", mesh.outputs.mesh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configure the servers\nMake a list of ip addresses an port numbers on which dpf servers are\nstarted. Workflows instances will be created on each of those servers to\naddress each a different result file.\nIn this example, we will post process an analysis distributed in 2 files,\nwe will consequently require 2 remote processes\nTo make this example easier, we will start local servers here,\nbut we could get connected to any existing servers on the network.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "remote_servers = [dpf.start_local_server(as_global=False), dpf.start_local_server(as_global=False)]\nips = [remote_server.ip for remote_server in remote_servers]\nports = [remote_server.port for remote_server in remote_servers]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the ips and ports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"ips:\", ips)\nprint(\"ports:\", ports)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Choose the file path\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_path = examples.distributed_msup_folder\nfiles = [base_path + r'/file0.mode', base_path + r'/file1.mode']\nfiles_aux = [base_path + r'/file0.rst', base_path + r'/file1.rst']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Send workflows on servers\nHere we create new instances on the server by copies of the template workflow\nWe also connect the data sources to those workflows\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "remote_workflows = []\nfor i, server in enumerate(remote_servers):\n    remote_workflows.append(template_workflow.create_on_other_server(server))\n    ds = dpf.DataSources(files[i])\n    ds.add_file_path(files_aux[i])\n    remote_workflows[i].connect(\"data_sources\", ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a local workflow for expansion\nIn this workflow we merge the modal basis, the meshes, read the modal response\nand expand the modal response with the modal basis\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "local_workflow = dpf.Workflow()\nmerge = ops.utility.merge_fields_containers()\nmerge_mesh = ops.utility.merge_meshes()\n\nds = dpf.DataSources(base_path + r'/file_load_1.rfrq')\nresponse = ops.result.displacement(data_sources=ds)\nresponse.inputs.mesh(merge_mesh.outputs.merges_mesh)\n\nexpansion = ops.math.modal_superposition(solution_in_modal_space=response, modal_basis=merge)\ncomponent = ops.logic.component_selector_fc(expansion, 1)\n\nlocal_workflow.add_operators([merge, response, expansion, merge_mesh, component])\nlocal_workflow.set_input_name(\"in0\", merge, 0)\nlocal_workflow.set_input_name(\"in1\", merge, 1)\nlocal_workflow.set_input_name(\"inmesh0\", merge_mesh, 0)\nlocal_workflow.set_input_name(\"inmesh1\", merge_mesh, 1)\n\nlocal_workflow.set_output_name(\"expanded\", component.outputs.fields_container)\nlocal_workflow.set_output_name(\"mesh\", merge_mesh.outputs.merges_mesh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connect the workflows together and get the output\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for i, server in enumerate(remote_servers):\n    local_workflow.connect_with(remote_workflows[i],\n                                {\"out\": \"in\" + str(i), \"outmesh\": \"inmesh\" + str(i)})\n\nfc = local_workflow.get_output(\"expanded\", dpf.types.fields_container)\nmerged_mesh = local_workflow.get_output(\"mesh\", dpf.types.meshed_region)\nmerged_mesh.plot(fc.get_field_by_time_complex_ids(1, 0))\nmerged_mesh.plot(fc.get_field_by_time_complex_ids(10, 0))\nprint(fc)\n\ndpf.server.shutdown_all_session_servers()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}