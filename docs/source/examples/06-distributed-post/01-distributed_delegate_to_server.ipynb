{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compute total displacement from distributed files with distributed post\nThis example shows how distributed files can be read and post processed\non distributed processes. After remote post processing of total displacement,\nresults a merged on the local process. In this example, the client is only\nconnected to the coordinator server. Connections to remote processes are only\ndone implicitly through the coordinator.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import dpf module and its examples files\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ansys.dpf import core as dpf\nfrom ansys.dpf.core import examples\nfrom ansys.dpf.core import operators as ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create the template workflow of total displacement\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "template_workflow = dpf.Workflow()\ndisplacement = ops.result.displacement()\nnorm = ops.math.norm_fc(displacement)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add the operators to the template workflow and name its inputs and outputs\nOnce workflow's inputs and outputs are named, they can be connected later on\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "template_workflow.add_operators([displacement, norm])\ntemplate_workflow.set_input_name(\"data_sources\", displacement.inputs.data_sources)\ntemplate_workflow.set_output_name(\"out\", norm.outputs.fields_container)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configure the servers\nMake a list of ip addresses an port numbers on which dpf servers are\nstarted. Workflows instances will be created on each of those servers to\naddress each a different result file.\nIn this example, we will post process an analysis distributed in 2 files,\nwe will consequently require 2 remote processes\nTo make this example easier, we will start local servers here,\nbut we could get connected to any existing servers on the network.\nWe only keep instances of remote_servers to start and keep those servers\nawaik. The purpose of this example is to show that we can do distributed\npost processing without opening channels between this client and\nthe remote processes\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "remote_servers = [dpf.start_local_server(as_global=False), dpf.start_local_server(as_global=False)]\nips = [remote_server.ip for remote_server in remote_servers]\nports = [remote_server.port for remote_server in remote_servers]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the ips and ports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"ips:\", ips)\nprint(\"ports:\", ports)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we show how we could send files in temporary directory if we were not\nin shared memory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "files = examples.download_distributed_files()\nserver_file_paths = [dpf.upload_file_in_tmp_folder(files[0], server=remote_servers[0]),\n                     dpf.upload_file_in_tmp_folder(files[1], server=remote_servers[1])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Send workflows on servers\nHere we create new instances on the server by copies of the template workflow\nWe also connect the data sources to those workflows.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "remote_workflows = []\nfor i, ip in enumerate(ips):\n    remote_workflows.append(template_workflow.create_on_other_server(ip=ip, port=ports[i]))\n    ds = dpf.DataSources(server_file_paths[i])\n    remote_workflows[i].connect(\"data_sources\", ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a local workflow able to merge the results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "local_workflow = dpf.Workflow()\nmerge = ops.utility.merge_fields_containers()\nlocal_workflow.add_operator(merge)\nlocal_workflow.set_input_name(\"in0\", merge, 0)\nlocal_workflow.set_input_name(\"in1\", merge, 1)\nlocal_workflow.set_output_name(\"merged\", merge.outputs.merged_fields_container)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connect the workflows together and get the output\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for i, ip in enumerate(ips):\n    local_workflow.connect_with(remote_workflows[i], (\"out\", \"in\" + str(i)))\n\nfc = local_workflow.get_output(\"merged\", dpf.types.fields_container)\nprint(fc)\nprint(fc[0].min().data)\nprint(fc[0].max().data)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}