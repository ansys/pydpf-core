
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples\06-distributed-post\03-distributed-msup_expansion.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_06-distributed-post_03-distributed-msup_expansion.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_06-distributed-post_03-distributed-msup_expansion.py:


.. _ref_distributed_msup:

Distributed modal superposition
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
This example shows how distributed files can be read and expanded
on distributed processes. The modal basis (2 distributed files) is read
on 2 remote servers and the modal response reading and the expansion is
done on a third server.

.. GENERATED FROM PYTHON SOURCE LINES 13-14

Import dpf module and its examples files

.. GENERATED FROM PYTHON SOURCE LINES 14-19

.. code-block:: default


    from ansys.dpf import core as dpf
    from ansys.dpf.core import examples
    from ansys.dpf.core import operators as ops








.. GENERATED FROM PYTHON SOURCE LINES 20-23

Create the template workflow
~~~~~~~~~~~~~~~~~~~~~~~~~~~~
this workflow will provide the modal basis and the mesh for each domain

.. GENERATED FROM PYTHON SOURCE LINES 23-28

.. code-block:: default


    template_workflow = dpf.Workflow()
    displacement = ops.result.displacement()
    mesh = ops.mesh.mesh_provider()








.. GENERATED FROM PYTHON SOURCE LINES 29-31

Add the operators to the template workflow and name its inputs and outputs
Once workflow's inputs and outputs are named, they can be connected later on

.. GENERATED FROM PYTHON SOURCE LINES 31-37

.. code-block:: default

    template_workflow.add_operators([displacement])
    template_workflow.set_input_name("data_sources", displacement.inputs.data_sources)
    template_workflow.set_input_name("data_sources", mesh.inputs.data_sources)
    template_workflow.set_output_name("out", displacement.outputs.fields_container)
    template_workflow.set_output_name("outmesh", mesh.outputs.mesh)








.. GENERATED FROM PYTHON SOURCE LINES 38-47

Configure the servers
~~~~~~~~~~~~~~~~~~~~~~
Make a list of ip addresses an port numbers on which dpf servers are
started. Workflows instances will be created on each of those servers to
address each a different result file.
In this example, we will post process an analysis distributed in 2 files,
we will consequently require 2 remote processes
To make this example easier, we will start local servers here,
but we could get connected to any existing servers on the network.

.. GENERATED FROM PYTHON SOURCE LINES 47-52

.. code-block:: default


    remote_servers = [dpf.start_local_server(as_global=False), dpf.start_local_server(as_global=False)]
    ips = [remote_server.ip for remote_server in remote_servers]
    ports = [remote_server.port for remote_server in remote_servers]








.. GENERATED FROM PYTHON SOURCE LINES 53-54

Print the ips and ports

.. GENERATED FROM PYTHON SOURCE LINES 54-57

.. code-block:: default

    print("ips:", ips)
    print("ports:", ports)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    ips: ['127.0.0.1', '127.0.0.1']
    ports: [50061, 50062]




.. GENERATED FROM PYTHON SOURCE LINES 58-59

Choose the file path

.. GENERATED FROM PYTHON SOURCE LINES 59-64

.. code-block:: default


    base_path = examples.distributed_msup_folder
    files = [base_path + r'/file0.mode', base_path + r'/file1.mode']
    files_aux = [base_path + r'/file0.rst', base_path + r'/file1.rst']








.. GENERATED FROM PYTHON SOURCE LINES 65-69

Send workflows on servers
~~~~~~~~~~~~~~~~~~~~~~~~~~
Here we create new instances on the server by copies of the template workflow
We also connect the data sources to those workflows

.. GENERATED FROM PYTHON SOURCE LINES 69-76

.. code-block:: default

    remote_workflows = []
    for i, server in enumerate(remote_servers):
        remote_workflows.append(template_workflow.create_on_other_server(server))
        ds = dpf.DataSources(files[i])
        ds.add_file_path(files_aux[i])
        remote_workflows[i].connect("data_sources", ds)








.. GENERATED FROM PYTHON SOURCE LINES 77-81

Create a local workflow for expansion
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In this workflow we merge the modal basis, the meshes, read the modal response
and expand the modal response with the modal basis

.. GENERATED FROM PYTHON SOURCE LINES 81-102

.. code-block:: default


    local_workflow = dpf.Workflow()
    merge = ops.utility.merge_fields_containers()
    merge_mesh = ops.utility.merge_meshes()

    ds = dpf.DataSources(base_path + r'/file_load_1.rfrq')
    response = ops.result.displacement(data_sources=ds)
    response.inputs.mesh(merge_mesh.outputs.merges_mesh)

    expansion = ops.math.modal_superposition(solution_in_modal_space=response, modal_basis=merge)
    component = ops.logic.component_selector_fc(expansion, 1)

    local_workflow.add_operators([merge, response, expansion, merge_mesh, component])
    local_workflow.set_input_name("in0", merge, 0)
    local_workflow.set_input_name("in1", merge, 1)
    local_workflow.set_input_name("inmesh0", merge_mesh, 0)
    local_workflow.set_input_name("inmesh1", merge_mesh, 1)

    local_workflow.set_output_name("expanded", component.outputs.fields_container)
    local_workflow.set_output_name("mesh", merge_mesh.outputs.merges_mesh)








.. GENERATED FROM PYTHON SOURCE LINES 103-105

Connect the workflows together and get the output
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 105-117

.. code-block:: default


    for i, server in enumerate(remote_servers):
        local_workflow.connect_with(remote_workflows[i],
                                    {"out": "in" + str(i), "outmesh": "inmesh" + str(i)})

    fc = local_workflow.get_output("expanded", dpf.types.fields_container)
    merged_mesh = local_workflow.get_output("mesh", dpf.types.meshed_region)
    merged_mesh.plot(fc.get_field_by_time_complex_ids(1, 0))
    merged_mesh.plot(fc.get_field_by_time_complex_ids(10, 0))
    print(fc)

    dpf.server.shutdown_all_session_servers()



.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /examples/06-distributed-post/images/sphx_glr_03-distributed-msup_expansion_001.png
          :alt: 03 distributed msup expansion
          :srcset: /examples/06-distributed-post/images/sphx_glr_03-distributed-msup_expansion_001.png
          :class: sphx-glr-multi-img

    *

      .. image-sg:: /examples/06-distributed-post/images/sphx_glr_03-distributed-msup_expansion_002.png
          :alt: 03 distributed msup expansion
          :srcset: /examples/06-distributed-post/images/sphx_glr_03-distributed-msup_expansion_002.png
          :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    DPF  Fields Container
      with 20 field(s)
      defined on labels: complex time 

      with:
      - field 0 {complex:  0, time:  1} with Nodal location, 1 components and 1065 entities.
      - field 1 {complex:  1, time:  1} with Nodal location, 1 components and 1065 entities.
      - field 2 {complex:  0, time:  2} with Nodal location, 1 components and 1065 entities.
      - field 3 {complex:  1, time:  2} with Nodal location, 1 components and 1065 entities.
      - field 4 {complex:  0, time:  3} with Nodal location, 1 components and 1065 entities.
      - field 5 {complex:  1, time:  3} with Nodal location, 1 components and 1065 entities.
      - field 6 {complex:  0, time:  4} with Nodal location, 1 components and 1065 entities.
      - field 7 {complex:  1, time:  4} with Nodal location, 1 components and 1065 entities.
      - field 8 {complex:  0, time:  5} with Nodal location, 1 components and 1065 entities.
      - field 9 {complex:  1, time:  5} with Nodal location, 1 components and 1065 entities.
      - field 10 {complex:  0, time:  6} with Nodal location, 1 components and 1065 entities.
      - field 11 {complex:  1, time:  6} with Nodal location, 1 components and 1065 entities.
      - field 12 {complex:  0, time:  7} with Nodal location, 1 components and 1065 entities.
      - field 13 {complex:  1, time:  7} with Nodal location, 1 components and 1065 entities.
      - field 14 {complex:  0, time:  8} with Nodal location, 1 components and 1065 entities.
      - field 15 {complex:  1, time:  8} with Nodal location, 1 components and 1065 entities.
      - field 16 {complex:  0, time:  9} with Nodal location, 1 components and 1065 entities.
      - field 17 {complex:  1, time:  9} with Nodal location, 1 components and 1065 entities.
      - field 18 {complex:  0, time:  10} with Nodal location, 1 components and 1065 entities.
      - field 19 {complex:  1, time:  10} with Nodal location, 1 components and 1065 entities.






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  5.186 seconds)


.. _sphx_glr_download_examples_06-distributed-post_03-distributed-msup_expansion.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: 03-distributed-msup_expansion.py <03-distributed-msup_expansion.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: 03-distributed-msup_expansion.ipynb <03-distributed-msup_expansion.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
