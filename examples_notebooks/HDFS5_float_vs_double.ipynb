{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 export: Compare the size between double/simple precision\n",
    "# -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st step : load dpf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "tmpdir = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ansys.dpf import core as dpf\n",
    "from ansys.dpf.core import operators as ops\n",
    "from ansys.dpf.core import examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = ops.utility.html_doc()\n",
    "doc.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd step : load the hdf5 plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpf.load_library(\"Ans.Dpf.Hdf5.dll\",\"hdf5\")\n",
    "from ansys.dpf.core import operators as ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd step: read stresses, displacements, and the mesh from an rst file and export it to hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transient = examples.download_transient_result()\n",
    "model = dpf.Model(transient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress = model.results.stress()\n",
    "displacement = model.results.displacement()\n",
    "mesh = model.metadata.meshed_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeIds = list(range(1,model.metadata.time_freq_support.n_sets+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, we only read the last time step, a user can request one or several time steps using the time_scoping input. Here we will request all time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress.inputs.time_scoping.connect(timeIds)\n",
    "displacement.inputs.time_scoping.connect(timeIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5op = ops.serialization.serialize_to_hdf5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPF serialize_to_hdf5 Operator: \n",
      "  Serialize the inputs in an hdf5 format. \n",
      "  Inputs:\n",
      "         file_path [string]: output file path with .h5 extension \n",
      "         export_floats [bool]: converts double to float to reduce file size (default is true) \n",
      "         export_flat_vectors [bool]: if true, vectors and matrices data are exported flat (x1,y1,z1,x2,y2,z2..) (default is false) \n",
      "         data (ellipsis) []: only the data set explicitly to export is exported \n",
      "  Run the operator to get its result\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(h5op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export to hdf5 with simple precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5op.inputs.file_path.connect(os.path.join(tmpdir,'c:/temp/dpf_float.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5op.inputs.data1.connect(stress.outputs)\n",
    "h5op.inputs.data2.connect(displacement.outputs)\n",
    "h5op.inputs.data3.connect(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5op.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export to hdf5 with double precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5op.inputs.export_floats.connect(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5op.inputs.file_path.connect(os.path.join(tmpdir,'c:/temp/dpf_double.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5op.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size with float precision: 6702616 \n",
      " size with double precision: 13111816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The batch file cannot be found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"size with float precision: {os.stat(os.path.join(tmpdir,'c:/temp/dpf_float.h5')).st_size} \\n size with double precision: {os.stat(os.path.join(tmpdir,'c:/temp/dpf_double.h5')).st_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
