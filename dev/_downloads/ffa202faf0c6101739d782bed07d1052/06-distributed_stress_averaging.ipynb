{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Average Stress in distributed Workflows {#ref_distributed_stress_averaging}\r\n\r\nThis example shows how stress can be read from distributed files and\r\naveraged from elemental nodal to nodal in parallel with a distributed\r\nworkflow. After remote post-processing, results are merged on the local\r\nprocess.\r\n\r\n::: note\r\n::: title\r\nNote\r\n:::\r\n\r\nThis example requires the Premium ServerContext. For more information,\r\nsee `user_guide_server_context`{.interpreted-text role=\"ref\"}.\r\n:::\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import dpf module and its examples files\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ansys.dpf import core as dpf\nfrom ansys.dpf.core import examples\nfrom ansys.dpf.core import operators as ops\n\n\ndpf.set_default_server_context(dpf.AvailableServerContexts.premium)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configure the servers\r\n\r\nMake a list of ip addresses and port numbers on which dpf servers are\r\nstarted. Workflow instances will be created on each of these servers to\r\naddress each a different result file. In this example, we will post\r\nprocess an analysis distributed in 2 files, we will consequently require\r\n2 remote processes. To make this example easier, we will start local\r\nservers here, but we could get connected to any existing servers on the\r\nnetwork.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "files = examples.download_distributed_files()\n\nconfig = dpf.ServerConfig(protocol=dpf.server.CommunicationProtocols.gRPC)\nremote_servers = [dpf.start_local_server(as_global=False, config=config) for file in files]\nips = [remote_server.ip for remote_server in remote_servers]\nports = [remote_server.port for remote_server in remote_servers]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the ips and ports\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"ips:\", ips)\nprint(\"ports:\", ports)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Distributed Workflow\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: graphviz\r\n\r\ndigraph foo {\r\n\r\n:   graph \\[pad=\\\"0\\\", nodesep=\\\"0.3\\\", ranksep=\\\"0.3\\\"\\] node\r\n    \\[shape=box, style=filled, fillcolor=\\\"#ffcc00\\\", margin=\\\"0\\\"\\];\r\n    rankdir=LR; splines=line;\r\n\r\n    stress01 \\[label=\\\"stress\\\"\\]; stress02 \\[label=\\\"stress\\\"\\];\r\n    average01 \\[label=\\\"elemental_nodal_to_nodal_fc\\\"\\]; average02\r\n    \\[label=\\\"elemental_nodal_to_nodal_fc\\\"\\];\r\n\r\n    subgraph cluster_1 {\r\n\r\n    :   ds01 \\[label=\\\"data_src\\\", shape=box, style=filled,\r\n        fillcolor=cadetblue2\\]; no_extend_to_mid_nodes01\r\n        \\[label=\\\"no_extend_to_mid_nodes\\\", shape=box, style=filled,\r\n        fillcolor=cadetblue2\\];\r\n\r\n        ds01 -\\> stress01 \\[style=dashed\\]; no_extend_to_mid_nodes01 -\\>\r\n        stress01 \\[style=dashed\\]; stress01 -\\> average01;\r\n\r\n        label=\\\"Server 2\\\"; style=filled; fillcolor=lightgrey;\r\n\r\n    }\r\n\r\n    subgraph cluster_2 {\r\n\r\n    :   ds02 \\[label=\\\"data_src\\\", shape=box, style=filled,\r\n        fillcolor=cadetblue2\\]; no_extend_to_mid_nodes02\r\n        \\[label=\\\"no_extend_to_mid_nodes\\\", shape=box, style=filled,\r\n        fillcolor=cadetblue2\\];\r\n\r\n        ds02 -\\> stress02 \\[style=dashed\\]; no_extend_to_mid_nodes02 -\\>\r\n        stress02 \\[style=dashed\\]; stress02 -\\> average02;\r\n\r\n        label=\\\"Server 1\\\"; style=filled; fillcolor=lightgrey;\r\n\r\n    } merge_weighted_fields_containers\r\n    \\[label=\\\"merge_weighted_fields_containers\\\"\\]; average01 -\\>\r\n    merge_weighted_fields_containers; average02 -\\>\r\n    merge_weighted_fields_containers; merge_weighted_fields_containers\r\n    -\\> extend_to_mid_nodes;\r\n\r\n}\r\n:::\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a local workflow able to merge the results\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "config = ops.utility.merge_weighted_fields_containers.default_config()\nconfig.set_read_inputs_in_parallel_option(True)\nmerge = ops.utility.merge_weighted_fields_containers(config=config)\nextend_to_mid_nodes = ops.averaging.extend_to_mid_nodes_fc(merge)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Send workflows on servers\r\n\r\nHere we create new instances on the server by copies of the template\r\nworkflow We also connect the data sources to those workflows\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "remote_workflows = []\nfor i, server in enumerate(remote_servers):\n    ds = dpf.DataSources(files[i], server=server)\n    stress = ops.result.stress(server=server)\n    stress.inputs.connect(ds)\n    average = ops.averaging.elemental_nodal_to_nodal_fc(stress)\n    average.inputs.extend_to_mid_nodes(False)\n\n    merge.connect(0 + i, average.outputs.fields_container)\n    merge.connect(1000 + i, average, 1)\n\nfc = extend_to_mid_nodes.outputs.fields_container()\nfc[0].plot()\nprint(fc)\nprint(fc[0].min().data)\nprint(fc[0].max().data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compare with non distributed Workflow\r\n\r\nCreate DataSources with Domain id (one domain by distributed file).\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ds = dpf.DataSources()\nds.set_domain_result_file_path(files[0], 0)\nds.set_domain_result_file_path(files[1], 1)\n\nmodel = dpf.Model(ds)\nstress = model.results.stress()\nfc_single_process = ops.averaging.to_nodal_fc(stress).eval()\n\nfc_single_process[0].plot()\nprint(fc_single_process[0].min().data)\nprint(fc_single_process[0].max().data)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}