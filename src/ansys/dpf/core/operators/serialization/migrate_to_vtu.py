"""
migrate_to_vtu

Autogenerated DPF operator classes.
"""

from __future__ import annotations

from warnings import warn
from ansys.dpf.core.dpf_operator import Operator
from ansys.dpf.core.inputs import Input, _Inputs
from ansys.dpf.core.outputs import Output, _Outputs
from ansys.dpf.core.operators.specification import PinSpecification, Specification
from ansys.dpf.core.config import Config
from ansys.dpf.core.server_types import AnyServerType


class migrate_to_vtu(Operator):
    r"""Extract all results from a datasources and exports them into vtu format.
    All the connected inputs are forwarded to the result providers
    operators.


    Parameters
    ----------
    time_scoping: Scoping, optional
        time sets to export, default is all
    streams_container: StreamsContainer, optional
        result file container allowed to be kept open to cache data
    data_sources: DataSources
        result file path container, used if no streams are set
    directory: str
        directory path
    base_name: str, optional
        vtu base file name, (default is file)
    result1: str, optional
        if Operator's names are connected to this Pin, only these results are exported (else all available results are exported)
    result2: str, optional
        if Operator's names are connected to this Pin, only these results are exported (else all available results are exported)
    write_mode: str, optional
        Available are rawbinarycompressed, rawbinary, base64appended, base64inline, ascii, default is (rawbinarycompressed)

    Returns
    -------
    path: DataSources
        list of output vtu file path

    Examples
    --------
    >>> from ansys.dpf import core as dpf

    >>> # Instantiate operator
    >>> op = dpf.operators.serialization.migrate_to_vtu()

    >>> # Make input connections
    >>> my_time_scoping = dpf.Scoping()
    >>> op.inputs.time_scoping.connect(my_time_scoping)
    >>> my_streams_container = dpf.StreamsContainer()
    >>> op.inputs.streams_container.connect(my_streams_container)
    >>> my_data_sources = dpf.DataSources()
    >>> op.inputs.data_sources.connect(my_data_sources)
    >>> my_directory = str()
    >>> op.inputs.directory.connect(my_directory)
    >>> my_base_name = str()
    >>> op.inputs.base_name.connect(my_base_name)
    >>> my_result1 = str()
    >>> op.inputs.result1.connect(my_result1)
    >>> my_result2 = str()
    >>> op.inputs.result2.connect(my_result2)
    >>> my_write_mode = str()
    >>> op.inputs.write_mode.connect(my_write_mode)

    >>> # Instantiate operator and connect inputs in one line
    >>> op = dpf.operators.serialization.migrate_to_vtu(
    ...     time_scoping=my_time_scoping,
    ...     streams_container=my_streams_container,
    ...     data_sources=my_data_sources,
    ...     directory=my_directory,
    ...     base_name=my_base_name,
    ...     result1=my_result1,
    ...     result2=my_result2,
    ...     write_mode=my_write_mode,
    ... )

    >>> # Get output data
    >>> result_path = op.outputs.path()
    """

    def __init__(
        self,
        time_scoping=None,
        streams_container=None,
        data_sources=None,
        directory=None,
        base_name=None,
        result1=None,
        result2=None,
        write_mode=None,
        config=None,
        server=None,
    ):
        super().__init__(name="migrate_to_vtu", config=config, server=server)
        self._inputs = InputsMigrateToVtu(self)
        self._outputs = OutputsMigrateToVtu(self)
        if time_scoping is not None:
            self.inputs.time_scoping.connect(time_scoping)
        if streams_container is not None:
            self.inputs.streams_container.connect(streams_container)
        if data_sources is not None:
            self.inputs.data_sources.connect(data_sources)
        if directory is not None:
            self.inputs.directory.connect(directory)
        if base_name is not None:
            self.inputs.base_name.connect(base_name)
        if result1 is not None:
            self.inputs.result1.connect(result1)
        if result2 is not None:
            self.inputs.result2.connect(result2)
        if write_mode is not None:
            self.inputs.write_mode.connect(write_mode)

    @staticmethod
    def _spec() -> Specification:
        description = r"""Extract all results from a datasources and exports them into vtu format.
All the connected inputs are forwarded to the result providers
operators.
"""
        spec = Specification(
            description=description,
            map_input_pin_spec={
                0: PinSpecification(
                    name="time_scoping",
                    type_names=["scoping", "vector<int32>"],
                    optional=True,
                    document=r"""time sets to export, default is all""",
                ),
                3: PinSpecification(
                    name="streams_container",
                    type_names=["streams_container"],
                    optional=True,
                    document=r"""result file container allowed to be kept open to cache data""",
                ),
                4: PinSpecification(
                    name="data_sources",
                    type_names=["data_sources"],
                    optional=False,
                    document=r"""result file path container, used if no streams are set""",
                ),
                20: PinSpecification(
                    name="directory",
                    type_names=["string"],
                    optional=False,
                    document=r"""directory path""",
                ),
                21: PinSpecification(
                    name="base_name",
                    type_names=["string"],
                    optional=True,
                    document=r"""vtu base file name, (default is file)""",
                ),
                30: PinSpecification(
                    name="result",
                    type_names=["string"],
                    optional=True,
                    document=r"""if Operator's names are connected to this Pin, only these results are exported (else all available results are exported)""",
                ),
                31: PinSpecification(
                    name="result",
                    type_names=["string"],
                    optional=True,
                    document=r"""if Operator's names are connected to this Pin, only these results are exported (else all available results are exported)""",
                ),
                100: PinSpecification(
                    name="write_mode",
                    type_names=["string"],
                    optional=True,
                    document=r"""Available are rawbinarycompressed, rawbinary, base64appended, base64inline, ascii, default is (rawbinarycompressed)""",
                ),
            },
            map_output_pin_spec={
                0: PinSpecification(
                    name="path",
                    type_names=["data_sources"],
                    optional=False,
                    document=r"""list of output vtu file path""",
                ),
            },
        )
        return spec

    @staticmethod
    def default_config(server: AnyServerType = None) -> Config:
        """Returns the default config of the operator.

        This config can then be changed to the user needs and be used to
        instantiate the operator. The Configuration allows to customize
        how the operation will be processed by the operator.

        Parameters
        ----------
        server:
            Server with channel connected to the remote or local instance. When
            ``None``, attempts to use the global server.

        Returns
        -------
        config:
            A new Config instance equivalent to the default config for this operator.
        """
        return Operator.default_config(name="migrate_to_vtu", server=server)

    @property
    def inputs(self) -> InputsMigrateToVtu:
        """Enables to connect inputs to the operator

        Returns
        --------
        inputs:
            An instance of InputsMigrateToVtu.
        """
        return super().inputs

    @property
    def outputs(self) -> OutputsMigrateToVtu:
        """Enables to get outputs of the operator by evaluating it

        Returns
        --------
        outputs:
            An instance of OutputsMigrateToVtu.
        """
        return super().outputs


class InputsMigrateToVtu(_Inputs):
    """Intermediate class used to connect user inputs to
    migrate_to_vtu operator.

    Examples
    --------
    >>> from ansys.dpf import core as dpf
    >>> op = dpf.operators.serialization.migrate_to_vtu()
    >>> my_time_scoping = dpf.Scoping()
    >>> op.inputs.time_scoping.connect(my_time_scoping)
    >>> my_streams_container = dpf.StreamsContainer()
    >>> op.inputs.streams_container.connect(my_streams_container)
    >>> my_data_sources = dpf.DataSources()
    >>> op.inputs.data_sources.connect(my_data_sources)
    >>> my_directory = str()
    >>> op.inputs.directory.connect(my_directory)
    >>> my_base_name = str()
    >>> op.inputs.base_name.connect(my_base_name)
    >>> my_result1 = str()
    >>> op.inputs.result1.connect(my_result1)
    >>> my_result2 = str()
    >>> op.inputs.result2.connect(my_result2)
    >>> my_write_mode = str()
    >>> op.inputs.write_mode.connect(my_write_mode)
    """

    def __init__(self, op: Operator):
        super().__init__(migrate_to_vtu._spec().inputs, op)
        self._time_scoping = Input(migrate_to_vtu._spec().input_pin(0), 0, op, -1)
        self._inputs.append(self._time_scoping)
        self._streams_container = Input(migrate_to_vtu._spec().input_pin(3), 3, op, -1)
        self._inputs.append(self._streams_container)
        self._data_sources = Input(migrate_to_vtu._spec().input_pin(4), 4, op, -1)
        self._inputs.append(self._data_sources)
        self._directory = Input(migrate_to_vtu._spec().input_pin(20), 20, op, -1)
        self._inputs.append(self._directory)
        self._base_name = Input(migrate_to_vtu._spec().input_pin(21), 21, op, -1)
        self._inputs.append(self._base_name)
        self._result1 = Input(migrate_to_vtu._spec().input_pin(30), 30, op, 0)
        self._inputs.append(self._result1)
        self._result2 = Input(migrate_to_vtu._spec().input_pin(31), 31, op, 1)
        self._inputs.append(self._result2)
        self._write_mode = Input(migrate_to_vtu._spec().input_pin(100), 100, op, -1)
        self._inputs.append(self._write_mode)

    @property
    def time_scoping(self) -> Input:
        r"""Allows to connect time_scoping input to the operator.

        time sets to export, default is all

        Returns
        -------
        input:
            An Input instance for this pin.

        Examples
        --------
        >>> from ansys.dpf import core as dpf
        >>> op = dpf.operators.serialization.migrate_to_vtu()
        >>> op.inputs.time_scoping.connect(my_time_scoping)
        >>> # or
        >>> op.inputs.time_scoping(my_time_scoping)
        """
        return self._time_scoping

    @property
    def streams_container(self) -> Input:
        r"""Allows to connect streams_container input to the operator.

        result file container allowed to be kept open to cache data

        Returns
        -------
        input:
            An Input instance for this pin.

        Examples
        --------
        >>> from ansys.dpf import core as dpf
        >>> op = dpf.operators.serialization.migrate_to_vtu()
        >>> op.inputs.streams_container.connect(my_streams_container)
        >>> # or
        >>> op.inputs.streams_container(my_streams_container)
        """
        return self._streams_container

    @property
    def data_sources(self) -> Input:
        r"""Allows to connect data_sources input to the operator.

        result file path container, used if no streams are set

        Returns
        -------
        input:
            An Input instance for this pin.

        Examples
        --------
        >>> from ansys.dpf import core as dpf
        >>> op = dpf.operators.serialization.migrate_to_vtu()
        >>> op.inputs.data_sources.connect(my_data_sources)
        >>> # or
        >>> op.inputs.data_sources(my_data_sources)
        """
        return self._data_sources

    @property
    def directory(self) -> Input:
        r"""Allows to connect directory input to the operator.

        directory path

        Returns
        -------
        input:
            An Input instance for this pin.

        Examples
        --------
        >>> from ansys.dpf import core as dpf
        >>> op = dpf.operators.serialization.migrate_to_vtu()
        >>> op.inputs.directory.connect(my_directory)
        >>> # or
        >>> op.inputs.directory(my_directory)
        """
        return self._directory

    @property
    def base_name(self) -> Input:
        r"""Allows to connect base_name input to the operator.

        vtu base file name, (default is file)

        Returns
        -------
        input:
            An Input instance for this pin.

        Examples
        --------
        >>> from ansys.dpf import core as dpf
        >>> op = dpf.operators.serialization.migrate_to_vtu()
        >>> op.inputs.base_name.connect(my_base_name)
        >>> # or
        >>> op.inputs.base_name(my_base_name)
        """
        return self._base_name

    @property
    def result1(self) -> Input:
        r"""Allows to connect result1 input to the operator.

        if Operator's names are connected to this Pin, only these results are exported (else all available results are exported)

        Returns
        -------
        input:
            An Input instance for this pin.

        Examples
        --------
        >>> from ansys.dpf import core as dpf
        >>> op = dpf.operators.serialization.migrate_to_vtu()
        >>> op.inputs.result1.connect(my_result1)
        >>> # or
        >>> op.inputs.result1(my_result1)
        """
        return self._result1

    @property
    def result2(self) -> Input:
        r"""Allows to connect result2 input to the operator.

        if Operator's names are connected to this Pin, only these results are exported (else all available results are exported)

        Returns
        -------
        input:
            An Input instance for this pin.

        Examples
        --------
        >>> from ansys.dpf import core as dpf
        >>> op = dpf.operators.serialization.migrate_to_vtu()
        >>> op.inputs.result2.connect(my_result2)
        >>> # or
        >>> op.inputs.result2(my_result2)
        """
        return self._result2

    @property
    def write_mode(self) -> Input:
        r"""Allows to connect write_mode input to the operator.

        Available are rawbinarycompressed, rawbinary, base64appended, base64inline, ascii, default is (rawbinarycompressed)

        Returns
        -------
        input:
            An Input instance for this pin.

        Examples
        --------
        >>> from ansys.dpf import core as dpf
        >>> op = dpf.operators.serialization.migrate_to_vtu()
        >>> op.inputs.write_mode.connect(my_write_mode)
        >>> # or
        >>> op.inputs.write_mode(my_write_mode)
        """
        return self._write_mode


class OutputsMigrateToVtu(_Outputs):
    """Intermediate class used to get outputs from
    migrate_to_vtu operator.

    Examples
    --------
    >>> from ansys.dpf import core as dpf
    >>> op = dpf.operators.serialization.migrate_to_vtu()
    >>> # Connect inputs : op.inputs. ...
    >>> result_path = op.outputs.path()
    """

    def __init__(self, op: Operator):
        super().__init__(migrate_to_vtu._spec().outputs, op)
        self._path = Output(migrate_to_vtu._spec().output_pin(0), 0, op)
        self._outputs.append(self._path)

    @property
    def path(self) -> Output:
        r"""Allows to get path output of the operator

        list of output vtu file path

        Returns
        -------
        output:
            An Output instance for this pin.

        Examples
        --------
        >>> from ansys.dpf import core as dpf
        >>> op = dpf.operators.serialization.migrate_to_vtu()
        >>> # Get the output from op.outputs. ...
        >>> result_path = op.outputs.path()
        """
        return self._path
